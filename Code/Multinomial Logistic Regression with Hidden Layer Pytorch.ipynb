{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from evaluate import *\n",
    "from load_test_set_pytorch import *\n",
    "from load_dataset_rgb_scale import *\n",
    "from __future__ import print_function\n",
    "from torch.autograd import Variable\n",
    "\n",
    "numClass = 43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39209, 64, 64, 3)\n",
      "(39209,)\n"
     ]
    }
   ],
   "source": [
    "X, Y = get_dataset_rgb_scale()\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_dimension(x):\n",
    "    x = np.transpose(x, (0, 3, 1, 2))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39209, 3, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "X = transpose_dimension(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #using \"same\" 2 times with relu then max pool from 64x64x3 to 32x32x9\n",
    "        self.conv1 = nn.Conv2d(3, 6, 9, padding=4) \n",
    "        self.conv2 = nn.Conv2d(6, 9, 9, padding=4) \n",
    "        #using \"same\" 2 times with relu then max pool from 32x32x9 to 16x16x15\n",
    "        self.conv3 = nn.Conv2d(9, 12, 7, padding=3) \n",
    "        self.conv4 = nn.Conv2d(12, 15, 7, padding=3) \n",
    "        #using \"same\" 2 times with relu then max pool from 16x16x15 to 8x8x21\n",
    "        self.conv5 = nn.Conv2d(15, 18, 5, padding=2) \n",
    "        self.conv6 = nn.Conv2d(18, 21, 5, padding=2) \n",
    "        #using \"same\" with maxpool with relu from 8x8x21 to 8x8x27 then to 4x4x27\n",
    "        self.conv7 = nn.Conv2d(21, 24, 3, padding=1)\n",
    "        self.conv8 = nn.Conv2d(24, 27, 3, padding=1)\n",
    "\n",
    "        #Fully connected layer\n",
    "        self.fc1 = nn.Linear(432, 300)\n",
    "        self.fc2 = nn.Linear(300, 200)\n",
    "        self.fc3 = nn.Linear(200, 200)\n",
    "        self.fc4 = nn.Linear(200, 128)\n",
    "        self.fc5 = nn.Linear(128, 128)\n",
    "        self.fc6 = nn.Linear(128, 64)\n",
    "        self.fc7 = nn.Linear(64, 64)\n",
    "        self.fc8 = nn.Linear(64, 64)\n",
    "        self.fc9 = nn.Linear(64, 43)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.conv1(X))\n",
    "        X = F.max_pool2d(F.relu(self.conv2(X)), (2,2))\n",
    "        X = F.relu(self.conv3(X))\n",
    "        X = F.max_pool2d(F.relu(self.conv4(X)), (2,2))\n",
    "        X = F.relu(self.conv5(X))\n",
    "        X = F.max_pool2d(F.relu(self.conv6(X)), (2,2))\n",
    "        X = F.relu(self.conv7(X))\n",
    "        X = F.max_pool2d(F.relu(self.conv8(X)), (2,2))\n",
    "    \n",
    "        X = X.view(-1, self.num_flat_features(X))\n",
    "        \n",
    "        X1 = F.relu(self.fc1(X)) #432 to 300\n",
    "        X2 = F.relu(self.fc2(X1)) #300 to 200\n",
    "        X3 = F.relu(self.fc3(X2)) #200 to 200\n",
    "        X4 = F.relu(self.fc4(X2 + X3)) #200 to 128\n",
    "        X5 = F.relu(self.fc5(X4)) #128 to 128\n",
    "        X6 = F.relu(self.fc6(X5 + X4)) #128 to 64\n",
    "        X7 = F.relu(self.fc7(X6)) #64 to 64\n",
    "        X8 = F.relu(self.fc8(X6 + X7)) #64 to 64\n",
    "        X9 = self.fc9(X8)\n",
    "\n",
    "        return X\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data(checkpoint_path, store_type,\n",
    "               learning_rate = (1e-4), num_epochs = 5, batch_size = 64, resume = False, num_class = 43):\n",
    "    net = Net()\n",
    "    start = time.time()\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    \n",
    "    m = X.shape[0]\n",
    "    iters_per_epoch = int(m / batch_size)+1\n",
    "    hist = []\n",
    "    \n",
    "    name_checkpoint = \"model_epoch\" + store_type + \".chkpt\"\n",
    "    \n",
    "    if (resume):\n",
    "        checkpoint = torch.load(os.path.join(checkpoint_path, name_checkpoint))\n",
    "        hist = checkpoint[\"hist\"]\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "        net.load_state_dict(checkpoint[\"net\"])\n",
    "    \n",
    "    cnt = 0\n",
    "    for param_group in optimizer.param_groups: \n",
    "        param_group['lr'] = learning_rate\n",
    "        cnt += 1\n",
    "    print(cnt)\n",
    "    \n",
    "    for iters in range(num_epochs):\n",
    "        for i in range(iters_per_epoch):\n",
    "            indices = np.random.choice(m, batch_size)\n",
    "#             print()\n",
    "            \n",
    "            input = X[indices]\n",
    "            target = Y[indices]\n",
    "            \n",
    "            input = Variable(torch.from_numpy(input).float())\n",
    "            target = Variable(torch.from_numpy(target).long())\n",
    "            \n",
    "            out = net(input)\n",
    "            loss = criterion(out, target)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            net.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if (i%40==0):\n",
    "                now = time.time()\n",
    "                print(\"iterate %d: loss = %.9f, spent = %.5f\" % (i + 1, loss.data[0], now - start))\n",
    "                start = now\n",
    "\n",
    "        print(\"Epoch %d: loss = %.9f\" % (iters + 1, loss.data[0]))\n",
    "        hist.append(loss.data[0])\n",
    "        \n",
    "    #\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    checkpoint = {\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "        \"hist\": hist,\n",
    "        \"net\": net.state_dict()\n",
    "    }\n",
    "    torch.save(checkpoint, os.path.join(checkpoint_path, name_checkpoint))\n",
    "    \n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "iterate 1: loss = 0.188046709, spent = 0.91788\n",
      "iterate 41: loss = 0.098726459, spent = 35.50823\n",
      "iterate 81: loss = 0.119357526, spent = 35.79569\n",
      "iterate 121: loss = 0.233187169, spent = 36.46851\n",
      "iterate 161: loss = 0.180718467, spent = 36.88355\n",
      "iterate 201: loss = 0.275977582, spent = 36.54720\n",
      "iterate 241: loss = 0.156635270, spent = 36.71249\n",
      "iterate 281: loss = 0.148248583, spent = 36.91655\n",
      "iterate 321: loss = 0.237905934, spent = 36.56615\n",
      "iterate 361: loss = 0.191249534, spent = 38.49671\n",
      "iterate 401: loss = 0.080186568, spent = 36.03751\n",
      "iterate 441: loss = 0.118834272, spent = 36.08990\n",
      "iterate 481: loss = 0.217800215, spent = 37.54166\n",
      "iterate 521: loss = 0.086915031, spent = 36.34997\n",
      "iterate 561: loss = 0.207074717, spent = 36.67723\n",
      "iterate 601: loss = 0.085938543, spent = 36.46018\n",
      "Epoch 1: loss = 0.070142679\n",
      "iterate 1: loss = 0.139630467, spent = 11.92226\n",
      "iterate 41: loss = 0.075974613, spent = 36.34908\n",
      "iterate 81: loss = 0.136316538, spent = 36.72448\n",
      "iterate 121: loss = 0.096741751, spent = 36.43411\n",
      "iterate 161: loss = 0.151872128, spent = 36.59992\n",
      "iterate 201: loss = 0.213303909, spent = 39.12078\n",
      "iterate 241: loss = 0.117768839, spent = 35.84892\n",
      "iterate 281: loss = 0.042988133, spent = 35.86186\n",
      "iterate 321: loss = 0.057645775, spent = 36.02137\n",
      "iterate 361: loss = 0.135435358, spent = 37.05004\n",
      "iterate 401: loss = 0.185709149, spent = 37.16143\n",
      "iterate 441: loss = 0.073401384, spent = 36.55554\n",
      "iterate 481: loss = 0.186007291, spent = 36.45948\n",
      "iterate 521: loss = 0.076534525, spent = 36.75344\n",
      "iterate 561: loss = 0.049839467, spent = 37.52898\n",
      "iterate 601: loss = 0.087827422, spent = 36.62901\n",
      "Epoch 2: loss = 0.122564755\n",
      "iterate 1: loss = 0.077744424, spent = 11.78384\n",
      "iterate 41: loss = 0.122345515, spent = 36.67628\n",
      "iterate 81: loss = 0.072560772, spent = 36.54862\n",
      "iterate 121: loss = 0.204360679, spent = 36.45278\n",
      "iterate 161: loss = 0.094270810, spent = 36.59681\n",
      "iterate 201: loss = 0.080391027, spent = 36.55893\n",
      "iterate 241: loss = 0.306256860, spent = 37.76814\n",
      "iterate 281: loss = 0.172439009, spent = 40.66582\n",
      "iterate 321: loss = 0.138610587, spent = 37.74234\n",
      "iterate 361: loss = 0.068528384, spent = 37.68374\n",
      "iterate 401: loss = 0.241441503, spent = 37.98108\n",
      "iterate 441: loss = 0.100087538, spent = 37.82631\n",
      "iterate 481: loss = 0.147525981, spent = 38.00234\n",
      "iterate 521: loss = 0.072210111, spent = 38.01761\n",
      "iterate 561: loss = 0.063713767, spent = 43.03926\n",
      "iterate 601: loss = 0.108374871, spent = 39.51918\n",
      "Epoch 3: loss = 0.077710047\n"
     ]
    }
   ],
   "source": [
    "hist = train_data(\"checkpoint\", \"11\", resume = True, num_epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.5182900428771973, 1.5142749547958374, 1.1461366415023804, 0.6217596530914307, 0.49422958493232727, 0.4902268946170807, 0.22011202573776245, 0.20778802037239075, 0.07014267891645432, 0.12256475538015366, 0.07771004736423492]\n",
      "11\n",
      "Net(\n",
      "  (conv1): Conv2d (3, 6, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4))\n",
      "  (conv2): Conv2d (6, 9, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4))\n",
      "  (conv3): Conv2d (9, 12, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "  (conv4): Conv2d (12, 15, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "  (conv5): Conv2d (15, 18, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv6): Conv2d (18, 21, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv7): Conv2d (21, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv8): Conv2d (24, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=432, out_features=300)\n",
      "  (fc2): Linear(in_features=300, out_features=200)\n",
      "  (fc3): Linear(in_features=200, out_features=200)\n",
      "  (fc4): Linear(in_features=200, out_features=128)\n",
      "  (fc5): Linear(in_features=128, out_features=128)\n",
      "  (fc6): Linear(in_features=128, out_features=64)\n",
      "  (fc7): Linear(in_features=64, out_features=64)\n",
      "  (fc8): Linear(in_features=64, out_features=64)\n",
      "  (fc9): Linear(in_features=64, out_features=43)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(os.path.join(\"checkpoint\", \"model_epoch11.chkpt\"))\n",
    "\n",
    "net = Net()\n",
    "\n",
    "hist = checkpoint[\"hist\"]\n",
    "net.load_state_dict(checkpoint[\"net\"])\n",
    "\n",
    "print(hist)\n",
    "print(len(hist))\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12630, 64, 64, 3)\n",
      "(12630,)\n"
     ]
    }
   ],
   "source": [
    "test_X, test_Y = load_test_set()\n",
    "print(test_X.shape)\n",
    "print(test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12630, 3, 64, 64)\n",
      "(3, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "test_X = transpose_dimension(test_X)\n",
    "print(test_X.shape)\n",
    "print(test_X[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outputs(net, instances):\n",
    "    instances = Variable(instances)\n",
    "    outputs = net(instances)\n",
    "    return outputs\n",
    "\n",
    "def evaluate(net, data_X, data_Y):\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    m = data_X.shape[0]\n",
    "\n",
    "    # Switch to evaluation mode.\n",
    "    net.eval()\n",
    "    \n",
    "    for i in range(m):\n",
    "        outputs = get_outputs(net, torch.from_numpy(data_X[i:i+1]).float())\n",
    "        labels = Variable(torch.from_numpy(data_Y[i:i+1]).long())\n",
    "\n",
    "        loss += nn.CrossEntropyLoss(size_average=False)(outputs, labels).data[0]\n",
    "\n",
    "        score, predicted = torch.max(outputs, 1)\n",
    "        now = (labels.data == predicted.data).sum()\n",
    "        correct += now\n",
    "        \n",
    "#         if (now==0):\n",
    "#             print(i)\n",
    "            \n",
    "        total += labels.size(0)\n",
    "\n",
    "    acc = correct / total\n",
    "    loss /= total\n",
    "\n",
    "    return loss, acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 1.188574\n",
      "Acc = 66.033254 percent\n",
      "Time per image: 0.007712 seconds: \n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "loss, acc = evaluate(net, test_X, test_Y)\n",
    "now = time.time()\n",
    "\n",
    "print(\"Loss = %.6f\" % (loss))\n",
    "print(\"Acc = %.6f percent\" % (acc*100))\n",
    "print(\"Time per image: %.6f seconds: \" % ((now-start)/test_X.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = evaluate(net, X, Y)\n",
    "\n",
    "print(\"Loss = %.6f\" % (loss))\n",
    "print(\"Acc = %.6f percent\" % (acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.5182900428771973, 1.5142749547958374, 1.1461366415023804, 0.6217596530914307, 0.49422958493232727, 0.4902268946170807, 0.22011202573776245, 0.20778802037239075, 0.07014267891645432, 0.12256475538015366, 0.07771004736423492]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9d407afc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss = 0.646080\n",
      "Test set acc = 86.104513 percent\n",
      "Time per image: 0.009311 seconds: \n"
     ]
    }
   ],
   "source": [
    "print(hist)\n",
    "plt.plot(hist)\n",
    "plt.ylabel('Loss of training set')\n",
    "plt.xlabel('Number of epoches')\n",
    "plt.show()\n",
    "\n",
    "start = time.time()\n",
    "loss, acc = evaluate(net, test_X, test_Y)\n",
    "now = time.time()\n",
    "print(\"Test set loss = %.6f\" % (loss))\n",
    "print(\"Test set acc = %.6f percent\" % (acc*100))\n",
    "print(\"Time per image: %.6f seconds: \" % ((now-start)/test_X.shape[0]))\n",
    "\n",
    "start = time.time()\n",
    "loss, acc = evaluate(net, X, Y)\n",
    "now = time.time()\n",
    "print(\"Train set loss = %.6f\" % (loss))\n",
    "print(\"Train set acc = %.6f percent\" % (acc*100))\n",
    "print(\"Time per image: %.6f seconds: \" % ((now-start)/X.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hist)\n",
    "plt.plot(hist)\n",
    "plt.ylabel('Loss of training set')\n",
    "plt.xlabel('Number of epoches')\n",
    "plt.show()\n",
    "\n",
    "start = time.time()\n",
    "loss, acc = evaluate(net, test_X, test_Y)\n",
    "now = time.time()\n",
    "print(\"Test set loss = %.6f\" % (loss))\n",
    "print(\"Test set acc = %.6f percent\" % (acc*100))\n",
    "print(\"Time per image: %.6f seconds \" % ((now-start)/test_X.shape[0]))\n",
    "\n",
    "start = time.time()\n",
    "loss, acc = evaluate(net, X, Y)\n",
    "now = time.time()\n",
    "print(\"Train set loss = %.6f\" % (loss))\n",
    "print(\"Train set acc = %.6f percent\" % (acc*100))\n",
    "print(\"Time per image: %.6f seconds \" % ((now-start)/X.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
